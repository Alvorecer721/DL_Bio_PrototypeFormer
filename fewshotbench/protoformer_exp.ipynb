{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.prot.swissprot import SPSetDataset\n",
    "from methods.protoformer import ProtoFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "\n",
    "# import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/u/0/uc?id=1a3IFmUMUXBH8trx_VWKZEGteRiotOkZS&export=download'\n",
    "\n",
    "# if os.path.exists('swissprot.zip'):\n",
    "#     print('File already downloaded.')\n",
    "# else:\n",
    "#     output = 'swissprot.zip'\n",
    "#     gdown.download(url, output, quiet=False)\n",
    "#     print('Download completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "\n",
    "# !unzip -q swissprot.zip\n",
    "\n",
    "# !rm -rf swissprot.zip\n",
    "# clear_output()\n",
    "\n",
    "# !mv data/swissprot/go-basic.obo ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Id(nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim):\n",
    "        super().__init__()\n",
    "        self.final_feat_dim = x_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:\n",
      "!gaf-version: 2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to validate header as GAF v2.2:\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMS:0:00:04.199775 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf \n",
      "25933 IDs in loaded association branch, BP\n",
      "\n",
      "**WARNING: NO VERSION LINE FOUND IN GAF FILE. USING:\n",
      "!gaf-version: 2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to validate header as GAF v2.2:\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMS:0:00:04.265576 310,057 annotations READ: ./data/swissprot/filtered_goa_uniprot_all_noiea.gaf \n",
      "25933 IDs in loaded association branch, BP\n"
     ]
    }
   ],
   "source": [
    "n_way, n_support, n_query, n_train_episode = 5, 5, 15, 5\n",
    "\n",
    "# Load train dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "train_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=n_train_episode, root='./data', mode='train')\n",
    "train_loader = train_dataset.get_data_loader()\n",
    "\n",
    "# Load test dataset. Remember to use make use of functions defined in the `SPSetDataset`.\n",
    "test_dataset = SPSetDataset(n_way, n_support, n_query, n_episode=100, root='./data', mode='test')\n",
    "test_loader = test_dataset.get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_way, n_support, n_query, n_train_episode, train_loader, test_loader, backbone):\n",
    "    wandb.init()\n",
    "    # Initialize model using the backbone and the optimizer.\n",
    "    # model = PrototypeFormer(backbone, n_way, n_support, n_sub_supports=n_support-1)\n",
    "    model = ProtoFormer(backbone, n_way, n_support, n_sub_support=4, n_layer=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "    test_accs = []; train_accs = []; train_losses = []\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "\n",
    "        epoch_loss = model.train_loop(epoch, train_loader, optimizer)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        train_acc = model.test_loop(train_loader)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        test_acc = model.test_loop(test_loader)\n",
    "        test_accs.append(test_acc)\n",
    "        print(f'Epoch {epoch} | Train Loss {epoch_loss} | Train Acc {train_acc} | Test Acc {test_acc}')\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 2.5))\n",
    "    ax1.plot(range(len(train_losses)), train_losses)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Train Loss')\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2.plot(range(len(test_accs)), test_accs)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Test Accuracy')\n",
    "    ax2.grid()\n",
    "    fig.suptitle(f\"n_way={n_way}, n_support={n_support}, n_query={n_query}, n_train_episode={n_train_episode}\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:j2h0egta) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524dabc610cb4b1bb37c9b93127bc02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/wandb/offline-run-20231207_211226-j2h0egta<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20231207_211226-j2h0egta/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:j2h0egta). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc650860d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Exception ignored in:   File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "_pickle.UnpicklingError: pickle data was truncated\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fc650860d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/xuyixuan/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "Epoch 0 | Batch 0/5 | Loss 1.619670\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "5 Test Acc = 71.73% +- 7.87%\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "100 Test Acc = 59.31% +- 1.46%\n",
      "Epoch 0 | Train Loss None | Train Acc 71.73333333333333 | Test Acc 59.30666666666666\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "Epoch 1 | Batch 0/5 | Loss 7.354900\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "5 Test Acc = 50.13% +- 10.73%\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "100 Test Acc = 58.79% +- 1.62%\n",
      "Epoch 1 | Train Loss None | Train Acc 50.133333333333326 | Test Acc 58.786666666666676\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "Epoch 2 | Batch 0/5 | Loss 3.176959\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "5 Test Acc = 59.20% +- 10.28%\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "100 Test Acc = 59.80% +- 1.48%\n",
      "Epoch 2 | Train Loss None | Train Acc 59.2 | Test Acc 59.8\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "Epoch 3 | Batch 0/5 | Loss 5.588009\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "5 Test Acc = 57.33% +- 9.11%\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2023-06-11) 46,420 Terms; optional_attrs(relationship)\n",
      "100 Test Acc = 58.72% +- 1.44%\n",
      "Epoch 3 | Train Loss None | Train Acc 57.333333333333336 | Test Acc 58.720000000000006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mWANDB_DISABLED\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m backbone \u001b[39m=\u001b[39m Id(train_dataset\u001b[39m.\u001b[39mx_dim)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_model(n_way, n_support, n_query, n_train_episode, train_loader, test_loader, backbone)\n",
      "\u001b[1;32m/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     epoch_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_loop(epoch, train_loader, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xuyixuan/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/protoformer_exp.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtest_loop(train_loader)\n",
      "File \u001b[0;32m~/Downloads/Project/DL_Bio_PrototypeFormer/fewshotbench/methods/meta_template.py:82\u001b[0m, in \u001b[0;36mMetaTemplate.train_loop\u001b[0;34m(self, epoch, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     79\u001b[0m print_freq \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     81\u001b[0m avg_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 82\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(train_loader):\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     84\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_query \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_support\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    437\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1032\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1040\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1041\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ML2023/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:189\u001b[0m, in \u001b[0;36mreduce_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    184\u001b[0m         t\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m requires_grad\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m--> 189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_tensor\u001b[39m(tensor):\n\u001b[1;32m    190\u001b[0m     storage \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39m_typed_storage()\n\u001b[1;32m    192\u001b[0m     \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mrequires_grad \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m tensor\u001b[39m.\u001b[39mis_leaf:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "backbone = Id(train_dataset.x_dim)\n",
    "\n",
    "train_model(n_way, n_support, n_query, n_train_episode, train_loader, test_loader, backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2023",
   "language": "python",
   "name": "ml2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
